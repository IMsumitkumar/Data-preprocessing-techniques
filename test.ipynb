{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "## These code is performed earlier and added to this pipeline one by one\n",
    "\n",
    "import datetime\n",
    "import calendar\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from collections import defaultdict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import (StandardScaler, MinMaxScaler,\n",
    "                                   RobustScaler, MaxAbsScaler,\n",
    "                                   PowerTransformer, QuantileTransformer,\n",
    "                                   OneHotEncoder, OrdinalEncoder,\n",
    "                                   KBinsDiscretizer)\n",
    "\n",
    "class Handle_Datatype(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,target,ml_usecase,categorical_features=[],numerical_features=[],time_features=[],features_todrop=[],display_types=True):\n",
    "        \n",
    "        self.target = target\n",
    "        self.ml_usecase= ml_usecase\n",
    "        self.categorical_features =categorical_features\n",
    "        self.numerical_features = numerical_features\n",
    "        self.time_features =time_features\n",
    "        self.features_todrop = features_todrop\n",
    "        self.display_types = display_types\n",
    "  \n",
    "    def fit(self,dataset,y=None):\n",
    "        data = dataset.copy()\n",
    "\n",
    "        # drop any columns that were asked to drop\n",
    "        data.drop(columns=self.features_todrop,errors='ignore',inplace=True)\n",
    "   \n",
    "        # if there are inf or -inf then replace them with NaN\n",
    "        data.replace([np.inf,-np.inf],np.NaN,inplace=True)\n",
    "\n",
    "        # also make sure that all the column names are string \n",
    "        data.columns = [str(i) for i in data.columns]\n",
    "          \n",
    "        # try to clean columns names\n",
    "        data.columns = data.columns.str.replace(r'[\\,\\}\\{\\]\\[\\:\\\"\\']','')\n",
    "   \n",
    "        # try to convert categoric columns into numerical if possible\n",
    "        for i in data.select_dtypes(include=['object']).columns:\n",
    "            try:\n",
    "                data[i] = data[i].astype('int64')\n",
    "            except:\n",
    "                None\n",
    "    \n",
    "        # convert pandas bool and categorical into categorical datatype\n",
    "        for i in data.select_dtypes(include=['bool', 'category']).columns:\n",
    "            data[i] = data[i].astype('object')\n",
    "    \n",
    "  \n",
    "        # with csv format, if we have any null in a colum that was int -> panda will read it as float.\n",
    "        for i in data.select_dtypes(include=['float64']).columns:\n",
    "            na_count = sum(data[i].isna())\n",
    "            # count how many digits are there that have decimiles\n",
    "            count_float = np.nansum([ False if r.is_integer() else True for r in data[i]])\n",
    "            # total decimiels digits\n",
    "            count_float = count_float - na_count # reducing it because we know NaN is counted as a float digit\n",
    "            # now if there isnt any float digit , & unique levales are less than 20 and there are Na's then convert it to object\n",
    "            if ( (count_float == 0) & (data[i].nunique() <=20) & (na_count>0) ):\n",
    "                data[i] = data[i].astype('object')\n",
    "        \n",
    "\n",
    "\n",
    "        for i in data.select_dtypes(include=['float64']).columns:\n",
    "            if data[i].nunique()==2:\n",
    "                data[i]= data[i].apply(str)\n",
    "\n",
    "\n",
    "        for i in data.select_dtypes(include=['object']).drop(self.target,axis=1,errors='ignore').columns:\n",
    "            try:\n",
    "                data[i] = pd.to_datetime(data[i], infer_datetime_format=True, utc=False, errors='raise')\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        # now in case we were given any specific columns dtypes in advance , we will over ride theos \n",
    "        for i in self.categorical_features:\n",
    "            try:\n",
    "                data[i]=data[i].apply(str)\n",
    "            except:\n",
    "                data[i]=dataset[i].apply(str)\n",
    "\n",
    "        for i in self.numerical_features:\n",
    "            try:\n",
    "                data[i]=data[i].astype('float64')\n",
    "            except:\n",
    "                data[i]=dataset[i].astype('float64')\n",
    "\n",
    "        for i in self.time_features:\n",
    "            try:\n",
    "                data[i] = pd.to_datetime(data[i], infer_datetime_format=True, utc=False, errors='raise')\n",
    "            except:\n",
    "                data[i] = pd.to_datetime(dataset[i], infer_datetime_format=True, utc=False, errors='raise')\n",
    "\n",
    "        for i in data.select_dtypes(include=['datetime64']).columns:\n",
    "            data[i] = data[i].astype('datetime64[ns]')\n",
    "\n",
    "        # table of learent types\n",
    "        self.learent_dtypes = data.dtypes\n",
    "        #self.training_columns = data.drop(self.target,axis=1).columns\n",
    "\n",
    "        # if there are inf or -inf then replace them with NaN\n",
    "        data = data.replace([np.inf,-np.inf],np.NaN).astype(self.learent_dtypes)\n",
    "        \n",
    "        # lets remove dupllicates\n",
    "        #remove columns with duplicate name \n",
    "        data = data.loc[:,~data.columns.duplicated()]\n",
    "        # Remove NAs\n",
    "        data.dropna(axis=0, how='all', inplace=True)\n",
    "        data.dropna(axis=1, how='all', inplace=True)\n",
    "        # remove the row if target column has NA\n",
    "        data = data[~data[self.target].isnull()]\n",
    "\n",
    "        return(data)\n",
    "\n",
    "    def transform(self,dataset,y=None):\n",
    "        data = dataset.copy()\n",
    "\n",
    "        # drop any columns that were asked to drop\n",
    "        data.drop(columns=self.features_todrop,errors='ignore',inplace=True)\n",
    "\n",
    "        # also make sure that all the column names are string \n",
    "        data.columns = [str(i) for i in data.columns]\n",
    "\n",
    "        # if there are inf or -inf then replace them with NaN\n",
    "        data.replace([np.inf,-np.inf],np.NaN,inplace=True)\n",
    "\n",
    "        # try to clean columns names\n",
    "        data.columns = data.columns.str.replace(r'[\\,\\}\\{\\]\\[\\:\\\"\\']','')\n",
    "\n",
    "        #very first thing we need to so is to check if the training and test data hace same columns\n",
    "        #exception checking   \n",
    "        import sys\n",
    "\n",
    "        for i in self.final_training_columns:\n",
    "            if i not in data.columns:\n",
    "                print('(Type Error): test data does not have column ' + str(i) + \" which was used for training\")\n",
    "\n",
    "        ## we only need to take test columns that we used in ttaining (test in production may have a lot more columns)\n",
    "        data = data[self.final_training_columns]\n",
    "\n",
    "        # just keep picking the data and keep applying to the test data set (be mindful of target variable)\n",
    "        for i in data.columns: # we are taking all the columns in test , so we dot have to worry about droping target columnself.lea\n",
    "            if self.learent_dtypes[i].name == 'datetime64[ns]':\n",
    "                data[i] = pd.to_datetime(data[i], infer_datetime_format=True, utc=False, errors='coerce')\n",
    "            data[i] = data[i].astype(self.learent_dtypes[i])\n",
    "\n",
    "        return(data)\n",
    "\n",
    "        # fit_transform\n",
    "    def fit_transform(self,dataset,y=None):\n",
    "\n",
    "        data= dataset.copy()\n",
    "        # drop any columns that were asked to drop\n",
    "        data.drop(columns=self.features_todrop,errors='ignore',inplace=True)\n",
    "\n",
    "        # since this is for training , we dont nees any transformation since it has already been transformed in fit\n",
    "        data = self.fit(data)\n",
    "\n",
    "        # additionally we just need to treat the target variable\n",
    "        # for ml use ase\n",
    "        if ((self.ml_usecase == 'classification') &  (data[self.target].dtype=='object')):\n",
    "            le = LabelEncoder()\n",
    "            data[self.target] = le.fit_transform(np.array(data[self.target]))\n",
    "\n",
    "            # now get the replacement dict\n",
    "            rev= le.inverse_transform(range(0,len(le.classes_)))\n",
    "            rep = np.array(range(0,len(le.classes_)))\n",
    "            self.replacement={}\n",
    "            for i,k in zip(rev,rep):\n",
    "                self.replacement[i] = k\n",
    "\n",
    "          # self.u = list(pd.unique(data[self.target]))\n",
    "          # self.replacement = np.arange(0,len(self.u))\n",
    "          # data[self.target]= data[self.target].replace(self.u,self.replacement)\n",
    "          # data[self.target] = data[self.target].astype('int64')\n",
    "          # self.replacement = pd.DataFrame(dict(target_variable=self.u,replaced_with=self.replacement))\n",
    "\n",
    "        # drop time columns\n",
    "        #data.drop(self.drop_time,axis=1,errors='ignore',inplace=True)\n",
    "\n",
    "        # drop id columns\n",
    "#         data.drop(self.id_columns,axis=1,errors='ignore',inplace=True)\n",
    "        # finally save a list of columns that we would need from test data set\n",
    "        self.final_training_columns = data.drop(self.target,axis=1).columns\n",
    "\n",
    "\n",
    "        return(data)\n",
    "\n",
    "class Handle_Missing(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target_variable, numeric_strategy, categorical_strategy):\n",
    "        self.target = target_variable\n",
    "        self.numeric_strategy = numeric_strategy\n",
    "        self.categorical_strategy = categorical_strategy\n",
    "        \n",
    "    def fit(self,dataset,y=None): #\n",
    "        def zeros(x):\n",
    "            return 0\n",
    "\n",
    "        data = dataset.copy()\n",
    "        # make a table for numerical variable with strategy stats\n",
    "        if self.numeric_strategy == 'mean':\n",
    "            self.numeric_stats = data.drop(self.target,axis=1).select_dtypes(include=['float64','int64']).apply(np.nanmean)\n",
    "        elif self.numeric_strategy == 'median':\n",
    "            self.numeric_stats = data.drop(self.target,axis=1).select_dtypes(include=['float64','int64']).apply(np.nanmedian)\n",
    "        else:\n",
    "            self.numeric_stats = data.drop(self.target,axis=1).select_dtypes(include=['float64','int64']).apply(zeros)\n",
    "\n",
    "        self.numeric_columns = data.drop(self.target,axis=1).select_dtypes(include=['float64','int64']).columns\n",
    "\n",
    "        #for Catgorical , \n",
    "        if self.categorical_strategy == 'most frequent':\n",
    "            self.categorical_columns = data.drop(self.target,axis=1).select_dtypes(include=['object']).columns\n",
    "            self.categorical_stats = pd.DataFrame(columns=self.categorical_columns) # place holder\n",
    "            for i in (self.categorical_stats.columns):\n",
    "                self.categorical_stats.loc[0,i] = data[i].value_counts().index[0]\n",
    "        else:\n",
    "            self.categorical_columns = data.drop(self.target,axis=1).select_dtypes(include=['object']).columns\n",
    "    \n",
    "        # for time, there is only one way, pick up the most frequent one\n",
    "        self.time_columns = data.drop(self.target,axis=1).select_dtypes(include=['datetime64[ns]']).columns\n",
    "        self.time_stats = pd.DataFrame(columns=self.time_columns) # place holder\n",
    "        for i in (self.time_columns):\n",
    "            self.time_stats.loc[0,i] = data[i].value_counts().index[0]\n",
    "        return(data)\n",
    "       \n",
    "    \n",
    "    def transform(self,dataset,y=None):\n",
    "        data = dataset.copy() \n",
    "        # for numeric columns\n",
    "        for i,s in zip(data[self.numeric_columns].columns,self.numeric_stats):\n",
    "            data[i].fillna(s,inplace=True)\n",
    "    \n",
    "        # for categorical columns\n",
    "        if self.categorical_strategy == 'most frequent':\n",
    "            for i in (self.categorical_stats.columns):\n",
    "                #data[i].fillna(self.categorical_stats.loc[0,i],inplace=True)\n",
    "                data[i] = data[i].fillna(self.categorical_stats.loc[0,i])\n",
    "                data[i] = data[i].apply(str)    \n",
    "        else:\n",
    "            # this means replace na with \"not_available\"\n",
    "            for i in (self.categorical_columns):\n",
    "                data[i].fillna(\"not_available\",inplace=True)\n",
    "                data[i] = data[i].apply(str)\n",
    "        # for time\n",
    "        for i in (self.time_stats.columns):\n",
    "            \n",
    "            data[i].fillna(self.time_stats.loc[0,i],inplace=True)\n",
    "    \n",
    "        return(data)\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data= dataset.copy()\n",
    "        \n",
    "        data = self.fit(data)\n",
    "        return self.transform(data)\n",
    "    \n",
    "\n",
    "class Handle_Zero_NearZero_Variance(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "        It eleminates the features having zero or near zero variance\n",
    "        Near Zero Variance is ddetermined by \n",
    "        - 1. count of unique points divided by the total length of the feature has to be lower than a prespecified threshold\n",
    "        - 2. Count of Most common point divided by the count of second most common point in the features is greater than a pre specified threshold\n",
    "        Once both are met than feature is dropped\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, target, threshold_1=0.1, threshold_2=20):\n",
    "        self.target = target\n",
    "        self.threshold_1 = threshold_1\n",
    "        self.threshold_2 = threshold_2\n",
    "        self.to_drop = []\n",
    "        \n",
    "    def fit(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.sample_len = len(data[self.target])\n",
    "        for i in data.drop(self.target, axis=1).columns:\n",
    "            u = pd.DataFrame(data[i].value_counts()).sort_values(by=i, ascending=False, inplace=False)\n",
    "            first = len(u)/self.sample_len\n",
    "            # Below : it means f column is non variance automaticaly make the number big to drop it \n",
    "            if len(u[i]) == 1:\n",
    "                second = 100\n",
    "            else:\n",
    "                second = u.iloc[0, 0] / u.iloc[1, 0]\n",
    "                \n",
    "            # If both conditions are met -> Drop the coumn\n",
    "            if (first <= self.threshold_1) and (second >= self.threshold_2) and (i[-10:] != '_surrogate'):\n",
    "                self.to_drop.append(i)\n",
    "            if (second == 100) and (i[-10:] != '_surrogate'):\n",
    "                self.to_drop.append(i)\n",
    "                \n",
    "    def transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        data.drop(self.to_drop, axis=1, inplace=True)\n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "class Group_Similiar_Features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, group_name=[], list_of_grouped_features=[[]]):\n",
    "        self.group_name = group_name\n",
    "        self.list_of_similar_features = list_of_grouped_features\n",
    "            \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        data =  dataset.copy()\n",
    "        if len(self.list_of_similar_features) > 0 and np.array(self.list_of_similar_features).shape[0] >= 1:\n",
    "            for f, g in zip(self.list_of_similar_features, self.group_name):\n",
    "                data[g + '_Min'] = data[f].apply(np.min, 1)\n",
    "                data[g + '_Max'] = data[f].apply(np.max, 1)\n",
    "                data[g + '_Mean'] = data[f].apply(np.mean, 1)\n",
    "                data[g + '_Median'] = data[f].apply(np.median, 1)\n",
    "                data[g + '_Mode'] = stats.mode(data[f], 1)[0]\n",
    "                data[g + '_Std'] = data[f].apply(np.std, 1)\n",
    "            return data\n",
    "        else:\n",
    "            return data\n",
    "        \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "class Scaling_and_Power_Transformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target, function_to_apply='zscore', random_state_quantile=42):\n",
    "        self.target = target\n",
    "        self.function_to_apply = function_to_apply\n",
    "        self.random_state_quantile = random_state_quantile\n",
    "        \n",
    "    def fit(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.numeric_features = data.drop(self.target, axis=1, errors='ignore').select_dtypes(include=['int64','float64']).columns\n",
    "        \n",
    "        # if there is any numerical feature\n",
    "        if len(self.numeric_features) > 0:\n",
    "            if self.function_to_apply == 'zscore':\n",
    "                self.scale_and_power = StandardScaler()\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            elif self.function_to_apply == 'minmax':\n",
    "                self.scale_and_power = MinMaxScaler()\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            elif self.function_to_apply == 'yj':\n",
    "                self.scale_and_power = PowerTransformer(method='yeo-johnson', standardize=True)\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            elif self.function_to_apply == 'quantile':\n",
    "                self.scale_and_power = QuantileTransformer(random_state=self.random_state_quantile,\n",
    "                                                          output_distribution='normal')\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            elif self.function_to_apply == 'robust':\n",
    "                self.scale_and_power = RobustScaler()\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            elif self.function_to_apply == 'maxabs':\n",
    "                self.scale_and_power = MaxAbsScaler()\n",
    "                self.scale_and_power.fit(data[self.numeric_features])\n",
    "            else:\n",
    "                return None\n",
    "        else:\n",
    "            None\n",
    "            \n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        if len(self.numeric_features) > 0:\n",
    "            self.data_t = pd.DataFrame(self.scale_and_power.transform(data[self.numeric_features]))\n",
    "            self.data_t.index = data.index\n",
    "            self.data_t.columns = self.numeric_features\n",
    "            for i in self.numeric_features:\n",
    "                data[i] = self.data_t[i]\n",
    "                \n",
    "            return data\n",
    "        else:\n",
    "            return data\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.fit(data)\n",
    "        return self.transform(data)\n",
    "\n",
    "class Target_Transformation(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target, function_to_apply='bc'):\n",
    "        self.target = target\n",
    "        self.function_to_apply = function_to_apply\n",
    "        if self.function_to_apply == 'bc':\n",
    "            self.function_to_apply = 'box-cox'\n",
    "        else:\n",
    "            self.function_to_apply = 'yeo-johnson'\n",
    "    \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        return dataset\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        \n",
    "        # if target column has zero or negative values then auto use yj method\n",
    "        if any(data[self.target] <= 0):\n",
    "            self.function_to_apply = 'yeo-johnson'\n",
    "        self.p_transform_target = PowerTransformer(method=self.function_to_apply)\n",
    "        \n",
    "        data[self.target] = self.p_transform_target.fit_transform(np.array(data[self.target]).reshape(-1, 1))\n",
    "        \n",
    "        return data\n",
    "\n",
    "class Make_Time_Features(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, time_features=[]):\n",
    "        self.time_features = time_features\n",
    "\n",
    "    \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "\n",
    "        for i in self.time_features:\n",
    "            try:\n",
    "                    data['day'] = data[i].dt.day\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['month'] = data[i].dt.month\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['year'] = data[i].dt.year\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['hour'] = data[i].dt.hour\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['minute'] = data[i].dt.minute\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['second'] = data[i].dt.second\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['quarter'] = data[i].dt.quarter\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['dayofweek'] = data[i].dt.dayofweek\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['weekday_name'] = data[i].dt.weekday_name\n",
    "                data['is_weekend'] = np.where(data['status_published'].isin(['Sunday','Saturday']),1,0)\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['dayofyear'] = data[i].dt.dayofyear\n",
    "            except:\n",
    "                None\n",
    "            try:\n",
    "                data['weekofyear'] = data[i].dt.weekofyear\n",
    "            except:\n",
    "                None\n",
    "\n",
    "        data.drop(self.time_features, axis=1, inplace=True)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        if not self.time_features:\n",
    "            self.time_features = data.select_dtypes(include=['datetime64[ns]']).columns\n",
    "        \n",
    "        return self.transform(data)\n",
    "\n",
    "class OrdinalEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self,target, ordinal_type, features_to_encode=[]):\n",
    "        self.target = target\n",
    "        self.ordinal_type = ordinal_type\n",
    "        self.features_to_encode = features_to_encode\n",
    "    \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        if ordinal_type == 'simple label':\n",
    "            for i in self.features_to_encode:\n",
    "                data[i] = self.le.fit_transform(data[i])\n",
    "        elif self.ordinal_type == 'target guided':\n",
    "            for i in self.features_to_encode:\n",
    "                data[i] = data[i].map(self.cat_dict)\n",
    "        else:\n",
    "            data = data\n",
    "            \n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        self.le = LabelEncoder()\n",
    "        if not self.features_to_encode:\n",
    "            self.features_to_encode = data.select_dtypes(include=['object']).columns\n",
    "            \n",
    "        if self.ordinal_type == 'simple label':\n",
    "            for i in self.features_to_encode:\n",
    "                data[i] = self.le.fit_transform(data[i])\n",
    "        elif self.ordinal_type == 'target guided':\n",
    "            for i in self.features_to_encode:\n",
    "                self.cat_labels = data.groupby([i])[self.target].mean().sort_values().index\n",
    "                self.cat_dict = {k:v for v,k in enumerate(self.cat_labels, 0)}\n",
    "                data[i] = data[i].map(self.cat_dict)\n",
    "        else:\n",
    "            data = data\n",
    "        \n",
    "        \n",
    "        return data\n",
    "\n",
    "class NominalEncoding(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, target, top, nominal_type, features_to_encode=[]):\n",
    "        self.target = target\n",
    "        self.top = top\n",
    "        self.nominal_type = nominal_type\n",
    "        self.features_to_encode = features_to_encode\n",
    "\n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        for i in self.features_to_encode:\n",
    "            if self.nominal_type == 'one hot' and len(data[i].unique()) > 20:\n",
    "                self.nominal_type = 'kdd orange'\n",
    "                \n",
    "            if self.nominal_type == 'one hot':\n",
    "                encoded_data = pd.get_dummies(data[i])\n",
    "                data = data.join(encoded_data, how='left').drop(columns=[i])\n",
    "                \n",
    "            elif self.nominal_type == 'kdd orange':\n",
    "                for cat in self.top_category:\n",
    "                    data[cat] = np.where(data.loc[:, i]==cat, 1, 0)\n",
    "                data.drop(columns=i,errors='ignore', inplace=True)\n",
    "                \n",
    "            elif self.nominal_type == 'mean encoding':\n",
    "                data[i] = data[i].map(self.mean_dict)\n",
    "            \n",
    "            elif self.nominal_type == 'frequency encoding':\n",
    "                data[i] = data[i].map(self.count_dict)\n",
    "                \n",
    "            else:\n",
    "                data = data\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        \n",
    "        if not self.features_to_encode:\n",
    "            self.features_to_encode = data.select_dtypes(include=['object']).columns\n",
    "        \n",
    "            \n",
    "        for i in self.features_to_encode:\n",
    "            if self.nominal_type == 'one hot' and len(data[i].unique()) > 20:\n",
    "                self.nominal_type = 'kdd orange'\n",
    "                \n",
    "            if self.nominal_type == 'one hot':\n",
    "                encoded_data = pd.get_dummies(data[i])\n",
    "                data = data.join(encoded_data, how='left').drop(columns=[i])\n",
    "                \n",
    "            elif self.nominal_type == 'kdd orange':\n",
    "                self.top_category = list(data[i].value_counts().sort_values(ascending=False).head(self.top).index)\n",
    "                for category in self.top_category:\n",
    "                    data[category] = np.where(data.loc[:,i]==category, 1, 0)\n",
    "                    \n",
    "                data.drop(columns=i, errors='ignore', inplace=True)\n",
    "                \n",
    "            elif self.nominal_type == 'mean encoding':\n",
    "                self.mean_dict = data.groupby([i])[self.target].mean().to_dict()\n",
    "                data[i] = data[i].map(self.mean_dict)\n",
    "                \n",
    "            elif self.nominal_type == 'frequency encoding':\n",
    "                self.count_dict = data[i].value_counts().to_dict()\n",
    "                data[i] = data[i].map(self.count_dict)\n",
    "                \n",
    "            else:\n",
    "                data = data\n",
    "            \n",
    "        return data\n",
    "            \n",
    "\n",
    "class Empty(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        return None\n",
    "    \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        return dataset\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        return self.transform(dataset)\n",
    "\n",
    "def Supervised_Path(train_data, target_variable, ml_usecase=None,\n",
    "                   test_data=None, categorical_features=[], numerical_features=[], \n",
    "                   time_features=[], features_to_drop=[],\n",
    "                   imputation_type=\"simple imputer\", numeric_imputation_strategy=\"mean\", categorical_imputation_strategy='most frequent',\n",
    "                   apply_zero_nearZero_variance=False,\n",
    "                   nominal_encoding=True, top=10, nominal_encoding_method = 'frequency encoding', features_for_nominal_encode=[],\n",
    "                   ordinal_encoding=True, ordinal_encoding_method = 'kdd orange', features_for_ordinal_encode=[],\n",
    "                   apply_grouping=False, group_name=[], features_to_group_ListofList=[[]],\n",
    "                   scale_data=False, scaling_method='zscore',\n",
    "                   target_transformation=False, target_transformation_method='bc',\n",
    "                   Power_transform_data=False, Power_transform_method='quantile',\n",
    "                   random_state=42):\n",
    "    \n",
    "    global subcase\n",
    "    \n",
    "    train_data.columns = [str(i) for i in train_data.columns]\n",
    "    if test_data is not None:\n",
    "        test_data.columns = [str(i) for i in test_data.columns]\n",
    "        \n",
    "    c1 = train_data[target_variable].dtype == 'int64'\n",
    "    c2 = train_data[target_variable].nunique() <= 20\n",
    "    c3 = train_data[target_variable].dtype.name in ['object', 'bool' 'category']\n",
    "    \n",
    "    if ml_usecase is None:\n",
    "        if (c1 & c2) | c3:\n",
    "            ml_usecase = 'classification'\n",
    "        else:\n",
    "            ml_usecase = 'regression'\n",
    "            \n",
    "    if (train_data[target_variable].nunique() > 2) and (ml_usecase != 'regression'):\n",
    "        subcase = 'multi'\n",
    "    else:\n",
    "        subcase = 'binary'\n",
    "        \n",
    "    dtypes = Handle_Datatype(target=target_variable, ml_usecase=ml_usecase, categorical_features=categorical_features,\n",
    "                            numerical_features=numerical_features, time_features=time_features, features_todrop=features_to_drop)\n",
    "    \n",
    "    if imputation_type == 'simple imputer':\n",
    "        try:\n",
    "            imputer = Handle_Missing(target_variable=target_variable, numeric_strategy=numeric_imputation_strategy,\n",
    "                                     categorical_strategy=categorical_imputation_strategy)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    else:\n",
    "        imputer = Empty()\n",
    "    \n",
    "\n",
    "    feature_time = Make_Time_Features()\n",
    "    \n",
    "    if apply_zero_nearZero_variance == True:\n",
    "        znz = Handle_Zero_NearZero_Variance(target=target_variable)\n",
    "    else:\n",
    "        znz = Empty()\n",
    "        \n",
    "    if apply_grouping == True:\n",
    "        group = Group_Similiar_Features(group_name=group_name, list_of_grouped_features=features_to_group_ListofList)\n",
    "    else:\n",
    "        group = Empty()\n",
    "        \n",
    "    if scale_data == True:\n",
    "        scaling = Scaling_and_Power_Transformation(target=target_variable, function_to_apply=scaling_method,\n",
    "                                                  random_state_quantile=random_state)\n",
    "    else:\n",
    "        scaling = Empty()\n",
    "    \n",
    "    if Power_transform_data == True:\n",
    "        p_transform = Scaling_and_Power_Transformation(target=target_variable, function_to_apply=Power_transform_method, \n",
    "                                                      random_state_quantile=random_state)\n",
    "    else:\n",
    "        p_transform = Empty()\n",
    "\n",
    "    if nominal_encoding == True:\n",
    "        nominal = NominalEncoding(target=target_variable, top=top, nominal_type = nominal_encoding_method, features_to_encode=features_for_nominal_encode)\n",
    "    else:\n",
    "        nominal = Empty()\n",
    "    \n",
    "    if ordinal_encoding == True:\n",
    "        ordinal = OrdinalEncoding(target=target_variable, ordinal_type=ordinal_encoding_method, features_to_encode=features_for_ordinal_encode)\n",
    "    else:\n",
    "        ordinal = Empty()\n",
    "\n",
    "    if (target_transformation == True) and (ml_usecase == 'regression'):\n",
    "        pt_target = Target_Transformation(target=target_variable, function_to_apply=target_transformation_method)\n",
    "    else:\n",
    "        pt_target = Empty()\n",
    "        \n",
    "        \n",
    "    pipe = Pipeline([\n",
    "        ('dtypes', dtypes),\n",
    "        ('imputer', imputer),\n",
    "        ('znz', znz),\n",
    "        ('group', group),\n",
    "        ('scaling', scaling),\n",
    "        ('p_transform', p_transform),\n",
    "        ('pt_target', pt_target),\n",
    "        ('feature_time', feature_time),\n",
    "        ('nominal', nominal),\n",
    "        ('ordinal', ordinal),\n",
    "    ])\n",
    "    \n",
    "    if test_data is not None:\n",
    "        return pipe.fit_transform(train_data), pipe.transform(test_data)\n",
    "    else:\n",
    "        return pipe.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"titanic.csv\")\n",
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([732., 106.,  31.,   2.,  11.,   6.,   0.,   0.,   0.,   3.]),\n",
       " array([  0.     ,  51.23292, 102.46584, 153.69876, 204.93168, 256.1646 ,\n",
       "        307.39752, 358.63044, 409.86336, 461.09628, 512.3292 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 508,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAARKElEQVR4nO3df6zddX3H8edrVNChsfy4Nk3brBgbDX+Mym5YjWZRiAbQWP5QIjGjIU26P9iC0UTLlmwx2R/4jyjJQtaIsyxORJTQIFG7gln2B+hFkF+VcSWQtin0yqBOiW7oe3+cT/VQ295ze38c7qfPR3JyPt/353Pu9/Ohh1e//dzvuTdVhSSpL3807glIkhae4S5JHTLcJalDhrskdchwl6QOrRj3BADOPffcWr9+/binIUnLyoMPPvizqpo4Vt9rItzXr1/P1NTUuKchSctKkmeP1+e2jCR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdeg18QnV+Vi//dtjO/czN3xwbOeWpBPxyl2SOmS4S1KHDHdJ6pDhLkkdMtwlqUOzhnuStyd5eOjx8ySfSHJ2kt1JnmrPZ7XxSXJTkukkjyS5cPGXIUkaNmu4V9WTVbWxqjYCfwa8DNwJbAf2VNUGYE87BrgM2NAe24CbF2HekqQTmOu2zCXAT6vqWWAzsLPVdwJXtPZm4NYauB9YmWT1QkxWkjSauYb7x4CvtfaqqjrY2s8Bq1p7DbBv6DX7W+1VkmxLMpVkamZmZo7TkCSdyMjhnuR04MPAN47uq6oCai4nrqodVTVZVZMTE8f8/a6SpJM0lyv3y4AfVdXz7fj5I9st7flQqx8A1g29bm2rSZKWyFzC/Sp+vyUDsAvY0tpbgLuG6le3u2Y2AYeHtm8kSUtgpB8cluRM4P3AXw2VbwBuT7IVeBa4stXvAS4HphncWXPNgs1WkjSSkcK9qn4JnHNU7QUGd88cPbaAaxdkdpKkk+InVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOjRTuSVYmuSPJT5LsTfKuJGcn2Z3kqfZ8VhubJDclmU7ySJILF3cJkqSjjXrl/kXgO1X1DuACYC+wHdhTVRuAPe0Y4DJgQ3tsA25e0BlLkmY1a7gneTPwF8AtAFX1v1X1ErAZ2NmG7QSuaO3NwK01cD+wMsnqBZ63JOkERrlyPw+YAf4lyUNJvpTkTGBVVR1sY54DVrX2GmDf0Ov3t9qrJNmWZCrJ1MzMzMmvQJL0B0YJ9xXAhcDNVfVO4Jf8fgsGgKoqoOZy4qraUVWTVTU5MTExl5dKkmYxSrjvB/ZX1QPt+A4GYf/8ke2W9nyo9R8A1g29fm2rSZKWyKzhXlXPAfuSvL2VLgGeAHYBW1ptC3BXa+8Crm53zWwCDg9t30iSlsCKEcf9DfDVJKcDTwPXMPiL4fYkW4FngSvb2HuAy4Fp4OU2VpK0hEYK96p6GJg8RtclxxhbwLXzm5YkaT78hKokdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUoZHCPckzSR5N8nCSqVY7O8nuJE+157NaPUluSjKd5JEkFy7mAiRJf2guV+7vq6qNVXXkF2VvB/ZU1QZgTzsGuAzY0B7bgJsXarKSpNHMZ1tmM7CztXcCVwzVb62B+4GVSVbP4zySpDkaNdwL+F6SB5Nsa7VVVXWwtZ8DVrX2GmDf0Gv3t9qrJNmWZCrJ1MzMzElMXZJ0PCtGHPeeqjqQ5C3A7iQ/Ge6sqkpSczlxVe0AdgBMTk7O6bWSpBMb6cq9qg6050PAncBFwPNHtlva86E2/ACwbujla1tNkrREZg33JGcmedORNvAB4DFgF7ClDdsC3NXau4Cr210zm4DDQ9s3kqQlMMq2zCrgziRHxv9bVX0nyQ+B25NsBZ4Frmzj7wEuB6aBl4FrFnzWkqQTmjXcq+pp4IJj1F8ALjlGvYBrF2R2kqST4idUJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA6NHO5JTkvyUJK72/F5SR5IMp3k60lOb/Uz2vF061+/SHOXJB3HXK7crwP2Dh1/Drixqt4GvAhsbfWtwIutfmMbJ0laQiOFe5K1wAeBL7XjABcDd7QhO4ErWntzO6b1X9LGS5KWyKhX7l8APg38th2fA7xUVa+04/3AmtZeA+wDaP2H23hJ0hKZNdyTfAg4VFUPLuSJk2xLMpVkamZmZiG/tCSd8ka5cn838OEkzwC3MdiO+SKwMsmKNmYtcKC1DwDrAFr/m4EXjv6iVbWjqiaranJiYmJei5Akvdqs4V5V11fV2qpaD3wMuLeqPg7cB3ykDdsC3NXau9oxrf/eqqoFnbUk6YTmc5/7Z4BPJplmsKd+S6vfApzT6p8Ets9vipKkuVox+5Dfq6rvA99v7aeBi44x5lfARxdgbpKkk+QnVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1KFZwz3J65P8IMmPkzye5LOtfl6SB5JMJ/l6ktNb/Yx2PN361y/yGiRJRxnlyv3XwMVVdQGwEbg0ySbgc8CNVfU24EVgaxu/FXix1W9s4yRJS2jWcK+BX7TD17VHARcDd7T6TuCK1t7cjmn9lyTJQk1YkjS7kfbck5yW5GHgELAb+CnwUlW90obsB9a09hpgH0DrPwycc4yvuS3JVJKpmZmZeS1CkvRqI4V7Vf2mqjYCa4GLgHfM98RVtaOqJqtqcmJiYr5fTpI0ZE53y1TVS8B9wLuAlUlWtK61wIHWPgCsA2j9bwZeWIjJSpJGM8rdMhNJVrb2G4D3A3sZhPxH2rAtwF2tvasd0/rvrapawDlLkmaxYvYhrAZ2JjmNwV8Gt1fV3UmeAG5L8o/AQ8AtbfwtwL8mmQb+G/jYIsxbknQCs4Z7VT0CvPMY9acZ7L8fXf8V8NEFmZ0k6aT4CVVJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6ZLhLUocMd0nqkOEuSR0y3CWpQ7OGe5J1Se5L8kSSx5Nc1+pnJ9md5Kn2fFarJ8lNSaaTPJLkwsVehCTp1Ua5cn8F+FRVnQ9sAq5Ncj6wHdhTVRuAPe0Y4DJgQ3tsA25e8FlLkk5o1nCvqoNV9aPW/h9gL7AG2AzsbMN2Ale09mbg1hq4H1iZZPVCT1ySdHxz2nNPsh54J/AAsKqqDrau54BVrb0G2Df0sv2tdvTX2pZkKsnUzMzMXOctSTqBkcM9yRuBbwKfqKqfD/dVVQE1lxNX1Y6qmqyqyYmJibm8VJI0i5HCPcnrGAT7V6vqW638/JHtlvZ8qNUPAOuGXr621SRJS2SUu2UC3ALsrarPD3XtAra09hbgrqH61e2umU3A4aHtG0nSElgxwph3A38JPJrk4Vb7W+AG4PYkW4FngStb3z3A5cA08DJwzUJOWJI0u1nDvar+E8hxui85xvgCrp3nvCRJ8+AnVCWpQ4a7JHXIcJekDhnuktQhw12SOmS4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOzRruSb6c5FCSx4ZqZyfZneSp9nxWqyfJTUmmkzyS5MLFnLwk6dhGuXL/CnDpUbXtwJ6q2gDsaccAlwEb2mMbcPPCTFOSNBcrZhtQVf+RZP1R5c3Ae1t7J/B94DOtfmtVFXB/kpVJVlfVwQWb8WvI+u3fHst5n7nhg2M5r6Tl42T33FcNBfZzwKrWXgPsGxq3v9UkSUto3t9QbVfpNdfXJdmWZCrJ1MzMzHynIUkacrLh/nyS1QDt+VCrHwDWDY1b22p/oKp2VNVkVU1OTEyc5DQkScdysuG+C9jS2luAu4bqV7e7ZjYBh3vdb5ek17JZv6Ga5GsMvnl6bpL9wD8ANwC3J9kKPAtc2YbfA1wOTAMvA9cswpwlSbMY5W6Zq47TdckxxhZw7XwnJUmaHz+hKkkdMtwlqUOGuyR1yHCXpA4Z7pLUIcNdkjpkuEtShwx3SeqQ4S5JHTLcJalDhrskdchwl6QOGe6S1CHDXZI6NOuP/NVrz7h+MTf4y7ml5cIrd0nqkOEuSR0y3CWpQ4a7JHXIcJekDi3K3TJJLgW+CJwGfKmqbliM8+jUMa47hLw7SMvVgod7ktOAfwLeD+wHfphkV1U9sdDnkhabt51quVqMK/eLgOmqehogyW3AZsBw78A4w05aLD3+Jb4Y4b4G2Dd0vB/486MHJdkGbGuHv0jy5Eme71zgZyf52uXoVFrvqbRWOGq9+dwYZ7L4TqU/2xOudZ5/zn9yvI6xfUK1qnYAO+b7dZJMVdXkAkxpWTiV1nsqrRVOrfW61sW3GHfLHADWDR2vbTVJ0hJZjHD/IbAhyXlJTgc+BuxahPNIko5jwbdlquqVJH8NfJfBrZBfrqrHF/o8Q+a9tbPMnErrPZXWCqfWel3rIktVjeO8kqRF5CdUJalDhrskdWhZh3uSS5M8mWQ6yfZxz2e+knw5yaEkjw3Vzk6yO8lT7fmsVk+Sm9raH0ly4fhmPndJ1iW5L8kTSR5Pcl2r97re1yf5QZIft/V+ttXPS/JAW9fX200IJDmjHU+3/vVjXcBJSHJakoeS3N2Oe17rM0keTfJwkqlWG+t7edmG+9CPObgMOB+4Ksn5453VvH0FuPSo2nZgT1VtAPa0Yxise0N7bANuXqI5LpRXgE9V1fnAJuDa9ufX63p/DVxcVRcAG4FLk2wCPgfcWFVvA14EtrbxW4EXW/3GNm65uQ7YO3Tc81oB3ldVG4fuaR/ve7mqluUDeBfw3aHj64Hrxz2vBVjXeuCxoeMngdWtvRp4srX/GbjqWOOW4wO4i8HPI+p+vcAfAz9i8MntnwErWv1372kGd5u9q7VXtHEZ99znsMa1DALtYuBuIL2utc37GeDco2pjfS8v2yt3jv1jDtaMaS6LaVVVHWzt54BVrd3N+ts/w98JPEDH623bFA8Dh4DdwE+Bl6rqlTZkeE2/W2/rPwycs6QTnp8vAJ8GftuOz6HftQIU8L0kD7YfrQJjfi/7C7KXkaqqJF3du5rkjcA3gU9U1c+T/K6vt/VW1W+AjUlWAncC7xjvjBZHkg8Bh6rqwSTvHfN0lsp7qupAkrcAu5P8ZLhzHO/l5Xzlfqr8mIPnk6wGaM+HWn3Zrz/J6xgE+1er6lut3O16j6iql4D7GGxNrExy5CJreE2/W2/rfzPwwtLO9KS9G/hwkmeA2xhszXyRPtcKQFUdaM+HGPzFfRFjfi8v53A/VX7MwS5gS2tvYbA3faR+dfvO+ybg8NA/AV/zMrhEvwXYW1WfH+rqdb0T7YqdJG9g8P2FvQxC/iNt2NHrPfLf4SPAvdU2aF/rqur6qlpbVesZ/H95b1V9nA7XCpDkzCRvOtIGPgA8xrjfy+P+RsQ8v4lxOfBfDPYu/27c81mA9XwNOAj8H4N9uK0M9h73AE8B/w6c3caGwd1CPwUeBSbHPf85rvU9DPYpHwEebo/LO17vnwIPtfU+Bvx9q78V+AEwDXwDOKPVX9+Op1v/W8e9hpNc93uBu3tea1vXj9vj8SNZNO73sj9+QJI6tJy3ZSRJx2G4S1KHDHdJ6pDhLkkdMtwlqUOGuyR1yHCXpA79P/hRDmLVWiVVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 5, 3, 4, 6])"
      ]
     },
     "execution_count": 509,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Parch'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Supervised_Path(train_data=data, target_variable='Survived',\n",
    "                    time_features=[], features_to_drop=['PassengerId'],numeric_imputation_strategy=\"mean\",\n",
    "                    categorical_imputation_strategy=\"most frequent\",\n",
    "                    apply_zero_nearZero_variance=True,\n",
    "                    apply_grouping=False, group_name='new', features_to_group_ListofList=[[]],\n",
    "                    nominal_encoding=True, top=10, nominal_encoding_method ='one hot', features_for_nominal_encode=[],\n",
    "                    ordinal_encoding=True, ordinal_encoding_method ='simple label', features_for_ordinal_encode=[],\n",
    "                    scale_data=True, scaling_method='minmax',\n",
    "                    target_transformation=True, Power_transform_data='bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Carlsson, Mr. Frans Olof</th>\n",
       "      <th>Cavendish, Mr. Tyrell William</th>\n",
       "      <th>Panula, Mrs. Juha (Maria Emilia Ojala)</th>\n",
       "      <th>Lefebre, Master. Henry Forbes</th>\n",
       "      <th>...</th>\n",
       "      <th>E101</th>\n",
       "      <th>F2</th>\n",
       "      <th>C22 C26</th>\n",
       "      <th>F33</th>\n",
       "      <th>D</th>\n",
       "      <th>D20</th>\n",
       "      <th>B57 B59 B63 B66</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass       Age  SibSp     Parch      Fare  \\\n",
       "0           0     1.0  0.271174  0.125  0.000000  0.014151   \n",
       "1           1     0.0  0.472229  0.125  0.000000  0.139136   \n",
       "2           1     1.0  0.321438  0.000  0.000000  0.015469   \n",
       "3           1     0.0  0.434531  0.125  0.000000  0.103644   \n",
       "4           0     1.0  0.434531  0.000  0.000000  0.015713   \n",
       "..        ...     ...       ...    ...       ...       ...   \n",
       "886         0     0.5  0.334004  0.000  0.000000  0.025374   \n",
       "887         1     0.0  0.233476  0.000  0.000000  0.058556   \n",
       "888         0     1.0  0.367921  0.125  0.333333  0.045771   \n",
       "889         1     0.0  0.321438  0.000  0.000000  0.058556   \n",
       "890         0     1.0  0.396833  0.000  0.000000  0.015127   \n",
       "\n",
       "     Carlsson, Mr. Frans Olof  Cavendish, Mr. Tyrell William  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "..                        ...                            ...   \n",
       "886                         0                              0   \n",
       "887                         0                              0   \n",
       "888                         0                              0   \n",
       "889                         0                              0   \n",
       "890                         0                              0   \n",
       "\n",
       "     Panula, Mrs. Juha (Maria Emilia Ojala)  Lefebre, Master. Henry Forbes  \\\n",
       "0                                         0                              0   \n",
       "1                                         0                              0   \n",
       "2                                         0                              0   \n",
       "3                                         0                              0   \n",
       "4                                         0                              0   \n",
       "..                                      ...                            ...   \n",
       "886                                       0                              0   \n",
       "887                                       0                              0   \n",
       "888                                       0                              0   \n",
       "889                                       0                              0   \n",
       "890                                       0                              0   \n",
       "\n",
       "     ...  E101  F2  C22 C26  F33  D  D20  B57 B59 B63 B66  S  C  Q  \n",
       "0    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "1    ...     0   0        0    0  0    0                0  0  1  0  \n",
       "2    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "3    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "4    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "..   ...   ...  ..      ...  ... ..  ...              ... .. .. ..  \n",
       "886  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "887  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "888  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "889  ...     0   0        0    0  0    0                0  0  1  0  \n",
       "890  ...     0   0        0    0  0    0                0  0  0  1  \n",
       "\n",
       "[891 rows x 41 columns]"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([732., 106.,  31.,   2.,  11.,   6.,   0.,   0.,   0.,   3.]),\n",
       " array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Outliers(BaseEstimator, TransformerMixin):\n",
    "    '''\n",
    "        Only takes numerical or one hot encoded data\n",
    "    '''\n",
    "    def __init__(self, target):\n",
    "        self.target = target\n",
    "        \n",
    "    def fit(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def transform(self, dataset, y=None):\n",
    "        return None\n",
    "    \n",
    "    def fit_transform(self, dataset, y=None):\n",
    "        data = dataset.copy()\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "from pyod.models.pca import PCA as PCA_RO\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "# https://machinelearningmastery.com/model-based-outlier-detection-and-removal-in-python/\n",
    "class Remove_Outliers(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,target,contamination=.20, random_state=42, methods=['knn','iso','mcd']):\n",
    "        \n",
    "        self.target = target\n",
    "        self.contamination = contamination\n",
    "        self.random_state = random_state\n",
    "        self.methods = methods\n",
    "\n",
    "    def fit(self,data,y=None):\n",
    "        return(None)\n",
    "\n",
    "    def transform(self,data,y=None):\n",
    "        return(data)\n",
    "\n",
    "    def fit_transform(self,dataset,y=None):\n",
    "        data = dataset.copy()\n",
    "        \n",
    "        if 'iso' in self.methods:\n",
    "            self.iso_forest = IForest(contamination=self.contamination,random_state=self.random_state,behaviour='new')\n",
    "            self.iso_forest.fit(data.drop(self.target,axis=1))\n",
    "            iso_predict = self.iso_forest.predict(data.drop(self.target,axis=1))\n",
    "            data['iso'] = iso_predict\n",
    "        \n",
    "        if 'knn' in self.methods:\n",
    "            self.knn_out = KNN(contamination=self.contamination)\n",
    "            self.knn_out.fit(data.drop(self.target,axis=1))\n",
    "            knn_predict = self.knn_out.predict(data.drop(self.target,axis=1))\n",
    "            data['knn'] = knn_predict\n",
    "            \n",
    "        if 'pca' in self.methods:\n",
    "            self.out_pca = PCA_RO(contamination=self.contamination,random_state=self.random_state)\n",
    "            self.out_pca.fit(data.drop(self.target,axis=1))\n",
    "            pca_predict = self.out_pca.predict(data.drop(self.target,axis=1))\n",
    "            data['pca'] = pca_predict\n",
    "        \n",
    "        # use for those features which are gaussian distributed\n",
    "        if 'mcd' in self.methods:\n",
    "            self.mcd = EllipticEnvelope(contamination=0.01)\n",
    "            self.mcd.fit(data.drop(self.target, axis=1))\n",
    "            mcd_predict = self.mcd.predict(data.drop(self.target, axis=1))\n",
    "            data['mcd'] = mcd_predict\n",
    "\n",
    "        data['vote_outlier'] = 0\n",
    "    \n",
    "        for i in self.methods:\n",
    "            data['vote_outlier'] = data['vote_outlier'] + data[i]\n",
    "    \n",
    "\n",
    "        self.outliers = data[data['vote_outlier']== len(self.methods)]\n",
    "    \n",
    "        return dataset[[True if i not in self.outliers.index else False for i in dataset.index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Remove_Outliers(target='Survived' ,methods=['iso','knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = obj.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Carlsson, Mr. Frans Olof</th>\n",
       "      <th>Cavendish, Mr. Tyrell William</th>\n",
       "      <th>Panula, Mrs. Juha (Maria Emilia Ojala)</th>\n",
       "      <th>Lefebre, Master. Henry Forbes</th>\n",
       "      <th>...</th>\n",
       "      <th>E101</th>\n",
       "      <th>F2</th>\n",
       "      <th>C22 C26</th>\n",
       "      <th>F33</th>\n",
       "      <th>D</th>\n",
       "      <th>D20</th>\n",
       "      <th>B57 B59 B63 B66</th>\n",
       "      <th>S</th>\n",
       "      <th>C</th>\n",
       "      <th>Q</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.271174</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014151</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.472229</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.139136</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015469</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.103644</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.434531</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.334004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025374</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.233476</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.367921</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.045771</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.321438</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058556</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.396833</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015127</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>770 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass       Age  SibSp     Parch      Fare  \\\n",
       "0           0     1.0  0.271174  0.125  0.000000  0.014151   \n",
       "1           1     0.0  0.472229  0.125  0.000000  0.139136   \n",
       "2           1     1.0  0.321438  0.000  0.000000  0.015469   \n",
       "3           1     0.0  0.434531  0.125  0.000000  0.103644   \n",
       "4           0     1.0  0.434531  0.000  0.000000  0.015713   \n",
       "..        ...     ...       ...    ...       ...       ...   \n",
       "886         0     0.5  0.334004  0.000  0.000000  0.025374   \n",
       "887         1     0.0  0.233476  0.000  0.000000  0.058556   \n",
       "888         0     1.0  0.367921  0.125  0.333333  0.045771   \n",
       "889         1     0.0  0.321438  0.000  0.000000  0.058556   \n",
       "890         0     1.0  0.396833  0.000  0.000000  0.015127   \n",
       "\n",
       "     Carlsson, Mr. Frans Olof  Cavendish, Mr. Tyrell William  \\\n",
       "0                           0                              0   \n",
       "1                           0                              0   \n",
       "2                           0                              0   \n",
       "3                           0                              0   \n",
       "4                           0                              0   \n",
       "..                        ...                            ...   \n",
       "886                         0                              0   \n",
       "887                         0                              0   \n",
       "888                         0                              0   \n",
       "889                         0                              0   \n",
       "890                         0                              0   \n",
       "\n",
       "     Panula, Mrs. Juha (Maria Emilia Ojala)  Lefebre, Master. Henry Forbes  \\\n",
       "0                                         0                              0   \n",
       "1                                         0                              0   \n",
       "2                                         0                              0   \n",
       "3                                         0                              0   \n",
       "4                                         0                              0   \n",
       "..                                      ...                            ...   \n",
       "886                                       0                              0   \n",
       "887                                       0                              0   \n",
       "888                                       0                              0   \n",
       "889                                       0                              0   \n",
       "890                                       0                              0   \n",
       "\n",
       "     ...  E101  F2  C22 C26  F33  D  D20  B57 B59 B63 B66  S  C  Q  \n",
       "0    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "1    ...     0   0        0    0  0    0                0  0  1  0  \n",
       "2    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "3    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "4    ...     0   0        0    0  0    0                0  1  0  0  \n",
       "..   ...   ...  ..      ...  ... ..  ...              ... .. .. ..  \n",
       "886  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "887  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "888  ...     0   0        0    0  0    0                0  1  0  0  \n",
       "889  ...     0   0        0    0  0    0                0  0  1  0  \n",
       "890  ...     0   0        0    0  0    0                0  0  0  1  \n",
       "\n",
       "[770 rows x 41 columns]"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([602.,   0.,  74.,   0.,  31.,   0.,   4.,   0.,   1.,   1.]),\n",
       " array([0.        , 0.08333333, 0.16666667, 0.25      , 0.33333333,\n",
       "        0.41666667, 0.5       , 0.58333333, 0.66666667, 0.75      ,\n",
       "        0.83333333]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(data['Parch'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f35879d6d00>"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Age'], data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f3587946370>"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Age'], data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f358782bd00>"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(data['Age'], data['Fare'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>make</th>\n",
       "      <th>fuel-type</th>\n",
       "      <th>aspiration</th>\n",
       "      <th>num-of-doors</th>\n",
       "      <th>body-style</th>\n",
       "      <th>drive-wheels</th>\n",
       "      <th>engine-location</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>...</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>fuel-system</th>\n",
       "      <th>bore</th>\n",
       "      <th>stroke</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>peak-rpm</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>13495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>convertible</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>88.6</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.47</td>\n",
       "      <td>2.68</td>\n",
       "      <td>9.0</td>\n",
       "      <td>111</td>\n",
       "      <td>5000</td>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alfa-romero</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>two</td>\n",
       "      <td>hatchback</td>\n",
       "      <td>rwd</td>\n",
       "      <td>front</td>\n",
       "      <td>94.5</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>2.68</td>\n",
       "      <td>3.47</td>\n",
       "      <td>9.0</td>\n",
       "      <td>154</td>\n",
       "      <td>5000</td>\n",
       "      <td>19</td>\n",
       "      <td>26</td>\n",
       "      <td>16500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>fwd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.8</td>\n",
       "      <td>...</td>\n",
       "      <td>109</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>102</td>\n",
       "      <td>5500</td>\n",
       "      <td>24</td>\n",
       "      <td>30</td>\n",
       "      <td>13950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>164.0</td>\n",
       "      <td>audi</td>\n",
       "      <td>gas</td>\n",
       "      <td>std</td>\n",
       "      <td>four</td>\n",
       "      <td>sedan</td>\n",
       "      <td>4wd</td>\n",
       "      <td>front</td>\n",
       "      <td>99.4</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>mpfi</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.4</td>\n",
       "      <td>8.0</td>\n",
       "      <td>115</td>\n",
       "      <td>5500</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>17450</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   symboling  normalized-losses         make fuel-type aspiration  \\\n",
       "0          3                NaN  alfa-romero       gas        std   \n",
       "1          3                NaN  alfa-romero       gas        std   \n",
       "2          1                NaN  alfa-romero       gas        std   \n",
       "3          2              164.0         audi       gas        std   \n",
       "4          2              164.0         audi       gas        std   \n",
       "\n",
       "  num-of-doors   body-style drive-wheels engine-location  wheel-base  ...  \\\n",
       "0          two  convertible          rwd           front        88.6  ...   \n",
       "1          two  convertible          rwd           front        88.6  ...   \n",
       "2          two    hatchback          rwd           front        94.5  ...   \n",
       "3         four        sedan          fwd           front        99.8  ...   \n",
       "4         four        sedan          4wd           front        99.4  ...   \n",
       "\n",
       "   engine-size  fuel-system  bore  stroke compression-ratio horsepower  \\\n",
       "0          130         mpfi  3.47    2.68               9.0        111   \n",
       "1          130         mpfi  3.47    2.68               9.0        111   \n",
       "2          152         mpfi  2.68    3.47               9.0        154   \n",
       "3          109         mpfi  3.19     3.4              10.0        102   \n",
       "4          136         mpfi  3.19     3.4               8.0        115   \n",
       "\n",
       "   peak-rpm city-mpg highway-mpg  price  \n",
       "0      5000       21          27  13495  \n",
       "1      5000       21          27  16500  \n",
       "2      5000       19          26  16500  \n",
       "3      5500       24          30  13950  \n",
       "4      5500       18          22  17450  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mobile = pd.read_csv('automobile.csv')\n",
    "auto_mobile.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>highway-mpg</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>202.000000</td>\n",
       "      <td>165.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>202.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.831683</td>\n",
       "      <td>121.836364</td>\n",
       "      <td>98.848020</td>\n",
       "      <td>174.273267</td>\n",
       "      <td>65.903960</td>\n",
       "      <td>53.775248</td>\n",
       "      <td>2558.173267</td>\n",
       "      <td>126.945545</td>\n",
       "      <td>10.160990</td>\n",
       "      <td>25.148515</td>\n",
       "      <td>30.658416</td>\n",
       "      <td>13253.752475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.258360</td>\n",
       "      <td>35.396412</td>\n",
       "      <td>6.094523</td>\n",
       "      <td>12.334330</td>\n",
       "      <td>2.106915</td>\n",
       "      <td>2.444769</td>\n",
       "      <td>517.236654</td>\n",
       "      <td>41.455269</td>\n",
       "      <td>3.995264</td>\n",
       "      <td>6.421956</td>\n",
       "      <td>6.809940</td>\n",
       "      <td>7954.919591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>141.100000</td>\n",
       "      <td>60.300000</td>\n",
       "      <td>47.800000</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5118.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.800000</td>\n",
       "      <td>64.125000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2174.250000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>8.600000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>7778.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>115.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>173.200000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2417.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>10320.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>102.400000</td>\n",
       "      <td>183.500000</td>\n",
       "      <td>66.825000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2932.750000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16502.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>120.900000</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>326.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>49.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>45400.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        symboling  normalized-losses  wheel-base      length       width  \\\n",
       "count  202.000000         165.000000  202.000000  202.000000  202.000000   \n",
       "mean     0.831683         121.836364   98.848020  174.273267   65.903960   \n",
       "std      1.258360          35.396412    6.094523   12.334330    2.106915   \n",
       "min     -2.000000          65.000000   86.600000  141.100000   60.300000   \n",
       "25%      0.000000          94.000000   94.500000  166.800000   64.125000   \n",
       "50%      1.000000         115.000000   97.000000  173.200000   65.500000   \n",
       "75%      2.000000         150.000000  102.400000  183.500000   66.825000   \n",
       "max      3.000000         256.000000  120.900000  208.100000   72.000000   \n",
       "\n",
       "           height  curb-weight  engine-size  compression-ratio    city-mpg  \\\n",
       "count  202.000000   202.000000   202.000000         202.000000  202.000000   \n",
       "mean    53.775248  2558.173267   126.945545          10.160990   25.148515   \n",
       "std      2.444769   517.236654    41.455269           3.995264    6.421956   \n",
       "min     47.800000  1488.000000    61.000000           7.000000   13.000000   \n",
       "25%     52.000000  2174.250000    98.000000           8.600000   19.000000   \n",
       "50%     54.100000  2417.000000   120.000000           9.000000   24.000000   \n",
       "75%     55.500000  2932.750000   141.000000           9.400000   30.000000   \n",
       "max     59.800000  4066.000000   326.000000          23.000000   49.000000   \n",
       "\n",
       "       highway-mpg         price  \n",
       "count   202.000000    202.000000  \n",
       "mean     30.658416  13253.752475  \n",
       "std       6.809940   7954.919591  \n",
       "min      16.000000   5118.000000  \n",
       "25%      25.000000   7778.250000  \n",
       "50%      30.000000  10320.000000  \n",
       "75%      34.000000  16502.250000  \n",
       "max      54.000000  45400.000000  "
      ]
     },
     "execution_count": 529,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_mobile.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Supervised_Path(train_data=auto_mobile, target_variable='price',\n",
    "                    time_features=[], features_to_drop=[''],numeric_imputation_strategy=\"mean\",\n",
    "                    categorical_imputation_strategy=\"most frequent\",\n",
    "                    apply_zero_nearZero_variance=True,\n",
    "                    apply_grouping=False, group_name='new', features_to_group_ListofList=[[]],\n",
    "                    nominal_encoding=True, top=10, nominal_encoding_method ='one hot', features_for_nominal_encode=[],\n",
    "                    ordinal_encoding=True, ordinal_encoding_method ='simple label', features_for_ordinal_encode=[],\n",
    "                    scale_data=False, scaling_method='minmax',\n",
    "                    target_transformation=True, Power_transform_data='bc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = Remove_Outliers(target='price' ,methods=['iso','knn'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = obj.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symboling</th>\n",
       "      <th>normalized-losses</th>\n",
       "      <th>wheel-base</th>\n",
       "      <th>length</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>curb-weight</th>\n",
       "      <th>engine-size</th>\n",
       "      <th>compression-ratio</th>\n",
       "      <th>city-mpg</th>\n",
       "      <th>...</th>\n",
       "      <th>4800</th>\n",
       "      <th>5500</th>\n",
       "      <th>5000</th>\n",
       "      <th>5200</th>\n",
       "      <th>5400</th>\n",
       "      <th>6000</th>\n",
       "      <th>5800</th>\n",
       "      <th>4500</th>\n",
       "      <th>5250</th>\n",
       "      <th>4150</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "      <td>186.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.860215</td>\n",
       "      <td>121.637634</td>\n",
       "      <td>98.440323</td>\n",
       "      <td>173.582796</td>\n",
       "      <td>65.712903</td>\n",
       "      <td>53.730645</td>\n",
       "      <td>2503.354839</td>\n",
       "      <td>122.623656</td>\n",
       "      <td>9.847957</td>\n",
       "      <td>25.311828</td>\n",
       "      <td>...</td>\n",
       "      <td>0.177419</td>\n",
       "      <td>0.193548</td>\n",
       "      <td>0.139785</td>\n",
       "      <td>0.107527</td>\n",
       "      <td>0.064516</td>\n",
       "      <td>0.043011</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.026882</td>\n",
       "      <td>0.037634</td>\n",
       "      <td>0.021505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.248492</td>\n",
       "      <td>31.376740</td>\n",
       "      <td>5.448872</td>\n",
       "      <td>11.367713</td>\n",
       "      <td>1.855291</td>\n",
       "      <td>2.317915</td>\n",
       "      <td>458.414132</td>\n",
       "      <td>33.443592</td>\n",
       "      <td>3.580325</td>\n",
       "      <td>5.947479</td>\n",
       "      <td>...</td>\n",
       "      <td>0.383054</td>\n",
       "      <td>0.396145</td>\n",
       "      <td>0.347700</td>\n",
       "      <td>0.310618</td>\n",
       "      <td>0.246333</td>\n",
       "      <td>0.203429</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.162174</td>\n",
       "      <td>0.190824</td>\n",
       "      <td>0.145453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>86.600000</td>\n",
       "      <td>144.600000</td>\n",
       "      <td>61.800000</td>\n",
       "      <td>48.800000</td>\n",
       "      <td>1819.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>166.300000</td>\n",
       "      <td>64.100000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>2145.000000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>8.525000</td>\n",
       "      <td>19.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>121.836364</td>\n",
       "      <td>96.750000</td>\n",
       "      <td>173.000000</td>\n",
       "      <td>65.400000</td>\n",
       "      <td>54.100000</td>\n",
       "      <td>2403.000000</td>\n",
       "      <td>110.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.750000</td>\n",
       "      <td>101.200000</td>\n",
       "      <td>180.200000</td>\n",
       "      <td>66.500000</td>\n",
       "      <td>55.500000</td>\n",
       "      <td>2821.750000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>256.000000</td>\n",
       "      <td>115.600000</td>\n",
       "      <td>202.600000</td>\n",
       "      <td>71.700000</td>\n",
       "      <td>59.800000</td>\n",
       "      <td>4066.000000</td>\n",
       "      <td>258.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 92 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        symboling  normalized-losses  wheel-base      length       width  \\\n",
       "count  186.000000         186.000000  186.000000  186.000000  186.000000   \n",
       "mean     0.860215         121.637634   98.440323  173.582796   65.712903   \n",
       "std      1.248492          31.376740    5.448872   11.367713    1.855291   \n",
       "min     -2.000000          65.000000   86.600000  144.600000   61.800000   \n",
       "25%      0.000000         101.000000   94.500000  166.300000   64.100000   \n",
       "50%      1.000000         121.836364   96.750000  173.000000   65.400000   \n",
       "75%      2.000000         140.750000  101.200000  180.200000   66.500000   \n",
       "max      3.000000         256.000000  115.600000  202.600000   71.700000   \n",
       "\n",
       "           height  curb-weight  engine-size  compression-ratio    city-mpg  \\\n",
       "count  186.000000   186.000000   186.000000         186.000000  186.000000   \n",
       "mean    53.730645  2503.354839   122.623656           9.847957   25.311828   \n",
       "std      2.317915   458.414132    33.443592           3.580325    5.947479   \n",
       "min     48.800000  1819.000000    70.000000           7.000000   15.000000   \n",
       "25%     52.000000  2145.000000    98.000000           8.525000   19.250000   \n",
       "50%     54.100000  2403.000000   110.000000           9.000000   25.000000   \n",
       "75%     55.500000  2821.750000   140.000000           9.400000   30.000000   \n",
       "max     59.800000  4066.000000   258.000000          23.000000   45.000000   \n",
       "\n",
       "       ...        4800        5500        5000        5200        5400  \\\n",
       "count  ...  186.000000  186.000000  186.000000  186.000000  186.000000   \n",
       "mean   ...    0.177419    0.193548    0.139785    0.107527    0.064516   \n",
       "std    ...    0.383054    0.396145    0.347700    0.310618    0.246333   \n",
       "min    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%    ...    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max    ...    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "             6000        5800        4500        5250        4150  \n",
       "count  186.000000  186.000000  186.000000  186.000000  186.000000  \n",
       "mean     0.043011    0.037634    0.026882    0.037634    0.021505  \n",
       "std      0.203429    0.190824    0.162174    0.190824    0.145453  \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000  \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 92 columns]"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
